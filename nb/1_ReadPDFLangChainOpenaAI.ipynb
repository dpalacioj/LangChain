{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute succesfully this notebook you should to install the following requirements:\n",
    "\n",
    "* `langchain==0.1.11`\n",
    "* `openai==1.13.3`\n",
    "* `PyPDF2==3.0.1`\n",
    "* `faiss-cpu==1.8.0`\n",
    "* `tiktoken==0.6.0`\n",
    "* `pandas`\n",
    "* `pydantic==2.6.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the openai key\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Carga las variables de entorno desde .env\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8556/1805202783.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key=open_api_key)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI parameters loaded into the class\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It is not specified who David Palacio is, so it is not possible to accurately answer this question. \n"
     ]
    }
   ],
   "source": [
    "our_query = \"How many awards did David Palacio won?\"\n",
    "print(llm.invoke(our_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.llms.openai.OpenAI"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Call a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PdfReader(r'../dpj_description.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'/Title': 'Documento sin t√≠tulo', '/Producer': 'Skia/PDF m132 Google Docs Renderer'}\n"
     ]
    }
   ],
   "source": [
    "print(len(data.pages))\n",
    "print(data.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "\n",
      "La cantidad de caracteres que tiene el pdf corresponden a: 652\n"
     ]
    }
   ],
   "source": [
    "combined_text = ''\n",
    "for i, page in enumerate(data.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        combined_text += text\n",
    "\n",
    "print(type(combined_text))\n",
    "print(\"\\n\")\n",
    "print(\"La cantidad de caracteres que tiene el pdf corresponden a: \" + str(len(combined_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['David\\nPalacio\\nis\\na\\nbilingual\\nArtificial\\nIntelligence\\nEngineer\\nwith\\na\\nstrong\\nbackground\\nin\\nstatistics,\\nmachine\\nlearning,\\nand\\ndeep\\nlearning.\\nHe\\nhas\\nexpertise\\nin\\nsupervised\\nlearning,\\nneural\\nnetworks,\\nNLP,\\nand\\nlarge\\nlanguage\\nmodels\\n(LLMs).\\nDavid\\nhas\\ndeveloped\\ninnovative\\nAI\\nsolutions\\nacross\\nvarious\\nindustries,\\nincluding\\nfinancial\\nestimations,\\nhealthcare,\\ngeological\\nrisk', 'geological\\nrisk\\nprediction,\\nand\\ngenerative\\nAI\\nfor\\ntreatment\\nplans.\\nHe\\nhas\\nextensive\\nexperience\\nin\\nMLOps,\\nhandling\\nend-to-end\\npipelines,\\ndeployment,\\nmonitoring,\\nand\\nCI/CD\\nimplementations.\\nPassionate\\nabout\\nleveraging\\ncutting-edge\\ntechnology,\\nhe\\nexcels\\nat\\ndriving\\nsuccess\\nand\\nimproving\\nteam\\nperformance.']\n",
      "\n",
      "\n",
      "<class 'list'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 370,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "finalData = text_splitter.split_text(combined_text)\n",
    "print(finalData)\n",
    "print(\"\\n\")\n",
    "print(type(finalData))\n",
    "print(len(finalData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geological\\nrisk\\nprediction,\\nand\\ngenerative\\nAI\\nfor\\ntreatment\\nplans.\\nHe\\nhas\\nextensive\\nexperience\\nin\\nMLOps,\\nhandling\\nend-to-end\\npipelines,\\ndeployment,\\nmonitoring,\\nand\\nCI/CD\\nimplementations.\\nPassionate\\nabout\\nleveraging\\ncutting-edge\\ntechnology,\\nhe\\nexcels\\nat\\ndriving\\nsuccess\\nand\\nimproving\\nteam\\nperformance.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finalData[0]\n",
    "finalData[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. To see more information click [here](https://python.langchain.com/docs/integrations/vectorstores/faiss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentSearch = FAISS.from_texts(finalData, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8556/3158837868.py:1: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(OpenAI(openai_api_key=open_api_key), chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "chain = load_qa_chain(OpenAI(openai_api_key=open_api_key), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8556/3335512588.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(input_documents=docs, question=our_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_query = \"How old is David Palacio?\"\n",
    "docs = documentSearch.similarity_search(our_query)\n",
    "chain.run(input_documents=docs, question=our_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
